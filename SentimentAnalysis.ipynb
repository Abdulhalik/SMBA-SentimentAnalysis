{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Women's E-Commerce data\n",
    "In this project we apply methods from Sentiment Analysis on the dataset \"Women's E-Commerce Clothing Reviews\" (https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews).\n",
    "\n",
    "## Content of the Dataset\n",
    "\n",
    "This dataset includes 23486 rows and 10 feature variables. Each row corresponds to a customer review, and includes the variables:\n",
    "\n",
    "- Clothing ID: Integer Categorical variable that refers to the specific piece being reviewed.\n",
    "- Age: Positive Integer variable of the reviewers age.\n",
    "- Title: String variable for the title of the review.\n",
    "- Review Text: String variable for the review body.\n",
    "- Rating: Positive Ordinal Integer variable for the product score granted by the customer from 1 Worst, to 5 Best.\n",
    "- Recommended IND: Binary variable stating where the customer recommends the product where 1 is recommended, 0 is not recommended.\n",
    "- Positive Feedback Count: Positive Integer documenting the number of other customers who found this review positive.\n",
    "- Division Name: Categorical name of the product high level division.\n",
    "- Department Name: Categorical name of the product department name.\n",
    "- Class Name: Categorical name of the product class name.\n",
    "\n",
    "## Approach\n",
    "The sentiment analysis of the clothing reviews is devided into the following 4 steps:\n",
    "1. Data pre-processing\n",
    "2. Build a lexicographic approach\n",
    "3. Build a supervised machine-learning model\n",
    "4. Evaluation and results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP libraries and regular expressions\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# Basic manipulation and numerics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLTK corpora and tools\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# function which does a train-test split for training a machine-learning model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of the data: \n",
      "['Clothing ID' 'Age' 'Title' 'Review Text' 'Rating' 'Recommended IND'\n",
      " 'Positive Feedback Count' 'Division Name' 'Department Name' 'Class Name'] \n"
     ]
    }
   ],
   "source": [
    "# read the data of 23486 Reviews of womens E-Commerce and 10 features\n",
    "data = pd.read_csv(\"data/WomensEcomm.csv\")\n",
    "data = data[data[\"Review Text\"].isna() == False] # remove samples without Review Text\n",
    "column_names = np.array(data.columns)[1:]\n",
    "\n",
    "# read in the dictionaries\n",
    "pos_words=open(\"data/positive_words.txt\",\"r\")\n",
    "pos_words=pos_words.read().split(\"\\n\")\n",
    "neg_words=open(\"data/negative_words.txt\",\"r\")\n",
    "neg_words=neg_words.read().split(\"\\n\")\n",
    "\n",
    "# Print the column names\n",
    "print(\"Columns of the data: \\n%s \" % column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first 5 columns of the data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0           0          767   33                      NaN   \n",
       "1           1         1080   34                      NaN   \n",
       "2           2         1077   60  Some major design flaws   \n",
       "3           3         1049   50         My favorite buy!   \n",
       "4           4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data pre-processing\n",
    "- Create a train-test split\n",
    "- Remove stopwords, punctuation and numbers and tokenize the sentences (done via process_sentence function)\n",
    "- Apply pre-processing on the whole data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data: Remove stop words, numbers and punctuation and tokenize the sentences\n",
    "train_data, test_data = train_test_split(data, test_size = 0.3)\n",
    "\n",
    "train_pos = train_data[ train_data[\"Recommended IND\"] == 1]\n",
    "train_neg = train_data[ train_data[\"Recommended IND\"] == 0]\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def process_sentence(sample):\n",
    "    word_tokens = word_tokenize(sample) \n",
    "\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "\n",
    "    filtered_sentence = [] \n",
    "\n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words and len(w) > 3: \n",
    "            filtered_sentence.append(w)\n",
    "    \n",
    "    return filtered_sentence\n",
    "\n",
    "# Processed Review Texts (Train-Set)\n",
    "train_data_text = [process_sentence(sentence) for sentence in train_data[\"Review Text\"]]\n",
    "# Processed Review Texts (Negative reviews)\n",
    "#train_data_neg = [process_sentence(sentence) for sentence in train_neg[\"Review Text\"]]\n",
    "# Processed Review Texts (Positive reviews)\n",
    "#train_data_pos = [process_sentence(sentence) for sentence in train_pos[\"Review Text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some example how the output of the pre-processing looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: \n",
      "These are super comfortable. i love feeling like i'm wearing pajamas in public but being properly dressed, although i wear them around the house often, too. i don't regret spending this much money on these pants, it was worth it since i'm wearing them so much. \n",
      "\n",
      "Pre-processed sentence:\n",
      "['These', 'super', 'comfortable', 'love', 'feeling', 'like', 'wearing', 'pajamas', 'public', 'properly', 'dressed', 'although', 'wear', 'around', 'house', 'often', 'regret', 'spending', 'much', 'money', 'pants', 'worth', 'since', 'wearing', 'much']\n"
     ]
    }
   ],
   "source": [
    "print(\"Original sentence: \\n%s \\n\" % train_data[\"Review Text\"].iloc[1])\n",
    "print(\"Pre-processed sentence:\\n%s\" % train_data_text[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lexicographic approach:\n",
    "Given a lexicon with words and their corresponding sentiments we count the number of negative and positive words.\n",
    "The lexicon originates from a Statistics for Social Data lecture of NYU and is available at: http://ptrckprry.com/course/ssd/. \n",
    "\n",
    "The following function: *get_sentiment_score* counts the number of positive and negative words in a given sentence given a list of positive words (*pos_words*) and negative words (*neg_words*). \n",
    "\n",
    "The prediction then is given by the ratio of positive over negative words. If there are more positive words then negative words we classify the sentence with a *1* (*positive sentiment*). If not it is *0* (*negative sentiment*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(sentence):\n",
    "    neg_cnt = 0\n",
    "    pos_cnt = 0\n",
    "    \n",
    "    for word in sentence:\n",
    "        if word in pos_words:\n",
    "            pos_cnt += 1\n",
    "        elif word in neg_words:\n",
    "            neg_cnt += 1\n",
    "    \n",
    "    if pos_cnt > neg_cnt:\n",
    "        return 1\n",
    "    \n",
    "    elif neg_cnt > pos_cnt:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Supervised Machine Learning Approach: Feature Extraction and Classifictation\n",
    "- Feature Extraction using word frequencies\n",
    "- classification using bayes theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: remove!!\n",
    "#Getting tupples of list of words and sentiment\n",
    "#train_data_pos_df = pd.DataFrame({'Text':train_data_pos})\n",
    "#train_data_pos_df['Sentiment'] = \"Positive\"\n",
    "#train_data_neg_df = pd.DataFrame({'Text':train_data_neg})\n",
    "#train_data_neg_df['Sentiment'] = \"Negative\"\n",
    "#frames = [train_data_pos_df, train_data_neg_df]\n",
    "#train_data1 = pd.concat(frames)\n",
    "\n",
    "train_data_with_labels = tuple(zip(train_data[\"Review Text\"], train_data[\"Recommended IND\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracts all words to an array\n",
    "def extract_features(document, train_corpus=train_data_with_labels):\n",
    "    def get_words_in_tweets(train_data):\n",
    "        all = []\n",
    "        for (words, sentiment) in train_data:\n",
    "            all.extend(words)\n",
    "        return all\n",
    "\n",
    "    #Measures frequency distribution\n",
    "    def get_word_features(wordlist):\n",
    "        wordlist = nltk.FreqDist(wordlist)\n",
    "        features = wordlist.keys()\n",
    "        return features\n",
    "\n",
    "    w_features = get_word_features(get_words_in_tweets(train_data_with_labels))\n",
    "\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in w_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Naive Bayes classifier\n",
    "training_set = nltk.classify.apply_features(extract_features, train_data_with_labels)\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting data for testing\n",
    "test_pos = test_data[ test_data[\"Recommended IND\"] == 1]['Review Text']\n",
    "test_neg = test_data[ test_data[\"Recommended IND\"] == 0]['Review Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring how the classifier algorithm scored.\n",
    "neg_cnt = 0\n",
    "pos_cnt = 0\n",
    "for obj in test_neg[:100]: \n",
    "    res =  classifier.classify(extract_features(obj.split()))\n",
    "    if(res == 'Negative'): \n",
    "        neg_cnt = neg_cnt + 1\n",
    "for obj in test_pos[:100]: \n",
    "    res =  classifier.classify(extract_features(obj.split()))\n",
    "    if(res == 'Positive'): \n",
    "        pos_cnt = pos_cnt + 1\n",
    "        \n",
    "print('[Negative]: %s/%s '  % (len(test_neg[:100]),neg_cnt))        \n",
    "print('[Positive]: %s/%s '  % (len(test_pos[:100]),pos_cnt)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring how the Lexicographic approach scored\n",
    "#sentiments = [get_sentiment_score(sentence) for sentence in train_data_text]\n",
    "#acc = np.mean([1 if pred  == label else 0 for pred, label in zip(sentiments, train_data[\"Recommended IND\"])])\n",
    "#acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
